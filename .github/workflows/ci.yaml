name: Build MLC LLM Runtime

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash -l {0}

    steps:

    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        submodules: recursive

    - name: Setup Miniconda
      uses: conda-incubator/setup-miniconda@v3
      with:
        auto-update-conda: true
        auto-activate-base: false
        activate-environment: mlc-chat-venv
        python-version: 3.13

    - name: Create build environment
      run: |
        conda create -y -n mlc-chat-venv -c conda-forge \
          "cmake>=3.24" \
          rust \
          git \
          python=3.13

    # âœ… FIXED STEP
    - name: Generate CMake config
      run: |
        conda activate mlc-chat-venv

        mkdir -p build
        cd build

        printf "\n n\n n\n n\n" | python ../cmake/gen_cmake_config.py

    - name: Build mlc_llm runtime
      run: |
        conda activate mlc-chat-venv
        cd build

        cmake ..
        make -j$(nproc)

    - name: Install Python package
      run: |
        conda activate mlc-chat-venv
        cd python

        pip install -e .

    - name: Validate build
      run: |
        conda activate mlc-chat-venv

        ls -l ./build/ | grep -E "libmlc_llm|libtvm_runtime" || true
        mlc_llm chat -h
        python -c "import mlc_llm; print(mlc_llm)"

    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      with:
        name: mlc-llm-build
        path: build/
