name: Build MLC LLM Runtime

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  build:
    name: Build mlc_llm from source
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash -l {0}

    steps:

    # 1Ô∏è‚É£ Checkout repository + submodules (TVM included)
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        submodules: recursive

    # 2Ô∏è‚É£ Setup Conda
    - name: Setup Miniconda
      uses: conda-incubator/setup-miniconda@v3
      with:
        auto-update-conda: true
        auto-activate-base: false
        activate-environment: mlc-chat-venv
        python-version: 3.13

    # 3Ô∏è‚É£ Create fresh build environment
    - name: Create build environment
      run: |
        conda create -y -n mlc-chat-venv -c conda-forge \
          "cmake>=3.24" \
          rust \
          git \
          python=3.13

    # 4Ô∏è‚É£ Generate CMake config (fully non-interactive)
    - name: Generate CMake config
      run: |
        conda activate mlc-chat-venv

        mkdir -p build
        cd build

        # Answers prompts automatically:
        # TVM path ‚Üí default
        # CUDA ‚Üí n
        # ROCm ‚Üí n
        # Vulkan ‚Üí n
        # Metal ‚Üí n
        # OpenCL ‚Üí n
        printf "\nn\nn\nn\nn\nn\n" | python ../cmake/gen_cmake_config.py

    # 5Ô∏è‚É£ Build mlc_llm runtime
    - name: Build mlc_llm runtime
      run: |
        conda activate mlc-chat-venv
        cd build

        cmake ..
        make -j$(nproc)

    # 6Ô∏è‚É£ Build TVM runtime libraries
    - name: Build TVM runtime
      run: |
        conda activate mlc-chat-venv
        cd 3rdparty/tvm

        mkdir -p build
        cd build

        cmake ..
        make -j$(nproc)

    # 7Ô∏è‚É£ Install TVM Python bindings
    - name: Install TVM Python bindings
      run: |
        conda activate mlc-chat-venv
        cd 3rdparty/tvm/python
        pip install -e .

    # 8Ô∏è‚É£ Install mlc_llm Python package
    - name: Install mlc_llm Python package
      run: |
        conda activate mlc-chat-venv
        cd python
        pip install -e .

    # 9Ô∏è‚É£ Install runtime Python dependencies
    - name: Install runtime Python dependencies
      run: |
        conda activate mlc-chat-venv
        pip install psutil numpy decorator attrs cloudpickle

    # üîü Export shared library paths
    - name: Export library paths
      run: |
        echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$(pwd)/build:$(pwd)/3rdparty/tvm/build" >> $GITHUB_ENV

    # 1Ô∏è‚É£1Ô∏è‚É£ Validate installation
    - name: Validate build
      run: |
        conda activate mlc-chat-venv

        echo "=== Build artifacts ==="
        ls -l ./build/ | grep libmlc || true
        ls -l ./3rdparty/tvm/build/ | grep libtvm || true

        echo "=== CLI test ==="
        mlc_llm chat -h

        echo "=== Python import test ==="
        python -c "import mlc_llm; print(mlc_llm)"

    # 1Ô∏è‚É£2Ô∏è‚É£ Upload artifacts
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: mlc-llm-build
        path: |
          build/
          3rdparty/tvm/build/
