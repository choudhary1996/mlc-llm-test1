name: linux build

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  Build-on-server:
    runs-on: ubuntu-24.04

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Setup Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: 3.13
          activate-environment: mlc-chat-venv
          channels: conda-forge
          channel-priority: strict

      - name: Recreate environment
        shell: bash -l {0}
        run: |
          conda env remove -n mlc-chat-venv || true
          conda create -n mlc-chat-venv -c conda-forge \
            "cmake>=3.24" rust git python=3.13 -y

      - name: Generate CMake config
        shell: bash -l {0}
        run: |
         printf "\nn\nn\nn\nn\nn\n" | python cmake/gen_cmake_config.py


      - name: Build TVM
        shell: bash -l {0}
        run: |
          cd 3rdparty/tvm
          rm -rf build
          mkdir build && cd build
          cmake .. \
            -DUSE_CUDA=OFF \
            -DUSE_CUBLAS=OFF \
            -DUSE_CUTLASS=OFF \
            -DBUILD_SHARED_LIBS=ON
          make -j$(nproc)
          ls libtvm.so libtvm_runtime.so

      - name: Build mlc-llm core
        shell: bash -l {0}
        run: |
          cd $GITHUB_WORKSPACE
          rm -rf build
          mkdir build && cd build
          cmake .. \
            -DUSE_CUDA=OFF \
            -DUSE_CUBLAS=OFF \
            -DUSE_CUTLASS=OFF \
            -DBUILD_SHARED_LIBS=ON
          make -j$(nproc)
          ls libmlc_llm.so libmlc_llm_module.so
          pip install numpy scipy psutil decorator attrs cloudpickle

      - name: Install MLC Python Package
        shell: bash -l {0}
        run: |
          cd $GITHUB_WORKSPACE
          pip install -e python
          export TVM_HOME=$GITHUB_WORKSPACE/3rdparty/tvm
          export TVM_LIBRARY_PATH=$TVM_HOME/build
          export LD_LIBRARY_PATH=$GITHUB_WORKSPACE/build:$TVM_LIBRARY_PATH:$LD_LIBRARY_PATH
          export PYTHONPATH=$GITHUB_WORKSPACE/python:$TVM_HOME/python:$PYTHONPATH

      - name: Verify
        shell: bash -l {0}
        run: |
          python - << 'EOF'
          import tvm
          print("TVM loaded OK, version:", tvm.__version__)
          EOF

          mlc_llm chat -h
